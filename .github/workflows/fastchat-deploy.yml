name: FastChat NPU Deploy
run-name: FastChat NPU Deploy

on:
  workflow_run:
    workflows: [FastChat NPU Inference]
    types:
      - completed

jobs:
  run_tests:
    runs-on: ascend-910b
    container:
      image: zhangsibo1129/ubuntu-cann-torch21-py39-fschat:latest
      volumes:
        - /usr/local/dcmi:/usr/local/dcmi
        - /usr/local/bin/npu-smi:/usr/local/bin/npu-smi
        - /usr/local/Ascend/driver/lib64:/usr/local/Ascend/driver/lib64
        - /usr/local/Ascend/driver/version.info:/usr/local/Ascend/driver/version.info
        - /data/disk3/action/models/hub/:/opt/big_models/
      options: --network host
               --device /dev/davinci_manager
               --device /dev/devmm_svm
               --device /dev/hisi_hdc
               --device /dev/davinci6
               --device /dev/davinci7
    steps:
        - name: Checkout Repo
          uses: actions/checkout@v4
          with:
            ssh-key: ${{ secrets.SECRET_SSH_KEY }}
            path: llm-tool-ci
            clean: false
        - name: Copy_Test_Cases
          working-directory: /__w/llm-tool-ci/llm-tool-ci/llm-tool-ci
          run: |
            cp fastchat_test/cases/deploy/* /root/FastChat/tests/

        - name: run_deploy_cases
          working-directory: /root/FastChat
          run: |
            cp tests/*.txt .
            nohup python tests/launch_openai_api_test_server.py > local_api.log 2>&1 &
            echo "wait 60s for deploy complete"
            sleep 60
            cat local_api.log
            python tests/test_local_api.py


